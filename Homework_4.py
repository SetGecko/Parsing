# ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠟⠏⢀⣀⣤⣤⣤⣤⣤⣤⣄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣿⣿⣿⣿⣿⣿⡿⣿⣴⢶⣶⣿⣟⣶⣿⣭⠿⠦⠤⠽⣷⣀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣿⣿⣿⣿⡿⢫⣿⢋⣠⣿⣿⡶⢻⡏⠄⠄⠄⠄⠄⠄⠄⠉⠙⢦⡀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣿⣿⡿⠋⠈⣸⣿⣿⣿⡿⠿⠄⠈⠃⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠙⣄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⢯⠋⠈⠄⣴⣿⣿⣿⣿⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠸⡄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⠒⠄⠄⢰⣿⣿⣿⣿⡇⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢷⡀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⠄⠄⠄⢼⣿⣿⣿⣿⡇⠄⠄⠄⠄⠄⢀⡀⠤⠤⠤⣀⠄⢀⡀⠤⠤⠤⣀⣱⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⠄⠄⠄⢸⣿⣿⣿⣿⣿⠄⠄⠄⢀⡖⠁⠄⠄⠄⠄⠄⠱⡏⠄⠄⠄⠄⠈⠱⡀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⠄⠄⠄⠄
# ⠄⠄⠄⠈⣿⣿⣿⣿⣿⡆⠄⠄⢸⠄⠄⠴⠆⠄⠄⠄⠄⠄⠄⠄⠄⠄⠶⠄⡇⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⣀⢀⡴⠋⠉⢹⡶⠶⢤
# ⠄⠄⠄⠄⢸⣿⣿⣿⣿⣿⣸⢻⡜⡄⠄⠄⠄⠄⠄⠄⢀⠶⠒⠒⠄⠐⣄⡼⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⣾⣿⣿⠟⠛⠓⠶⣏⠄⠄⣀
# ⠄⠄⠄⢸⢧⣿⣿⣿⣿⣿⡿⠄⠷⠙⠲⠄⠄⡀⠠⠔⠁⠄⠄⠄⢀⣠⡇⡧⠄⠄⠄⠄⠄⠄⠄⠄⠄⣴⣿⣿⣿⡇⠄⡀⠄⠄⠈⢦⠞⠁
# ⠄⠄⠄⢸⡈⢻⣿⣿⣿⡿⠧⣄⠄⠄⠄⢀⡴⠖⠒⠚⠛⠛⠛⠛⠉⠄⠈⠙⠦⣀⣠⣀⠄⠄⠄⠄⢰⣿⣿⣿⣿⠄⠄⠈⢢⡀⠠⢾⠄⠄
# ⠄⠄⠄⠄⣴⣾⣿⣿⣿⢲⡶⡄⠄⢀⡶⠋⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢁⠄⢸⠄⠄⠄⠄⣸⣿⣿⠟⠋⠄⠄⠄⡎⠄⠄⠈⠉⠄
# ⡀⠄⠄⠘⣿⣿⣿⣿⣿⣦⣤⡴⠄⣾⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢰⡷⢰⠃⠄⠄⣠⣾⣿⠟⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣠
# ⠙⢦⡀⠄⠈⠛⢻⣿⣿⣿⣿⡇⠄⣿⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢦⣀⣠⠎⢀⣤⣾⡿⠋⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⠞⠄
# ⠄⠄⠈⠳⢄⠄⢸⣿⣿⣿⣿⡇⠄⠙⣆⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⡴⠃⠄⣠⣴⣿⠟⠋⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⡰⠁⠄⠄
# ⠄⠄⠄⠄⠈⠙⢾⣿⣿⣿⣿⡇⠄⠄⠈⠳⠤⣀⡀⠄⠄⢀⣀⠤⡖⠋⢀⡤⠾⠿⣏⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣠⠎⠄⠄⠄⠄
# ⠄⠄⠄⠄⠄⠄⠄⢨⠇⠙⢿⠷⠖⠒⠛⠓⠒⠚⠛⠯⡉⠉⠄⠄⡷⠶⠯⡁⠄⠄⠄⠙⠢⡀⠄⠄⠄⠄⠄⠄⠄⠄⢀⠜⠁⠄⠄⠄⠄⠄
# ⠄⠄⠄⠄⠄⠄⢀⡌⠄⠄⠄⠳⡀⠄⠄⠄⠄⠄⡌⠄⠙⢆⠄⠄⡧⠂⠄⢡⠄⠄⠄⠄⠄⠈⠢⡀⠄⠄⠄⠄⢀⡔⠁⠄⠄⠄⠄⠄⠄⠄
# ⠄⠄⠄⠄⠄⢀⠌⠄⠄⠄⠄⠄⠰⡀⠄⠄⠄⢰⠃⠄⠄⠈⠣⡴⠉⠡⡀⠈⡆⠄⠄⠄⠄⠄⠄⠘⠄⠄⢀⡴⠊⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⠄⠄⠄⠄⡠⠊⠄⠄⠄⠄⠄⠄⠄⢩⠉⠉⠉⠉⠄⠄⠄⠄⠄⠄⠄⠄⠱⡀⠁⠄⠄⠄⠄⠄⠄⠄⠈⣶⠊⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣷⣄⣠⠞⠁⠄⠄⠄⠄⠄⠄⠄⠄⠈⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢡⠄⠄⠄⠄⠄⠄⠄⠄⢠⠎⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣿⣎⡁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠈⡆⠄⠄⠄⠄⢀⡠⠞⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⣿⣿⣿⣶⣤⣀⣀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠠⢤⡤⠴⠒⠊⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄
# ⠻⠿⢿⣿⣿⣿⣿⠏⠉⠉⠁⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠉⠢⡀⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄

import re
from datetime import date
from pprint import pprint

from lxml import html

from utilities import connect_2_db_server, validate_arguments, create_url, get_response, save_result_in_db, validate_data

def get_lenta_news(dom):
    list_of_news = []
    news_list = dom.xpath("//a[contains(@class, '_topnews')]")

    for news in news_list:
        news_info = {}
        name_of_the_news = news.xpath(
            ".//h3[@class='card-big__title']/text() | "
            ".//span[@class='card-mini__title']/text()"
        )
        news_link = news.xpath(".//@href")
        news_date = re.search(r'\d{4}.\d{2}.\d{2}|\d{2}.\d{2}.\d{4}', news_link[0])

        # из-за того, что новости могут быть региональными аля "moslenta", то доавим колдовства
        if 'https' in news_link[0]:
            news_source = re.search(r'^https:\/\/\w*.\w*', news_link[0])
            news_source = news_source.group()
        else:
            news_source = 'list.ru'

        news_info['source'] = news_source
        news_info['name'] = name_of_the_news[0]
        news_info['link'] = f'https://lenta.ru{news_link[0]}'
        news_info['date'] = news_date.group()

        list_of_news.append(news_info)

    return list_of_news

def get_mail_ru_news(dom):
    # тырим ссылочки на новости :)
    news_link_list = dom.xpath(
            "//a[contains(@class, 'js-topnews__item')]/@href | "
            "//li[@class='list__item']/a[@class='list__text']/@href")

    list_of_news = []
    for link in news_link_list:
        news_info = {}
        response = get_response(link)
        dom = html.fromstring(response.text)
        news = dom.xpath("//div[contains(@class, 'article js-article')]")[0]

        name_of_the_news = news.xpath(".//h1[@class='hdr__inner']/text()")
        news_date = news.xpath(".//span[contains(@class, 'js-ago')]/@datetime")
        news_source = news.xpath(".//a[contains(@class, 'breadcrumbs__link')]//text()")

        news_info['name'] = name_of_the_news[0]
        news_info['link'] = link
        news_info['date'] = news_date[0]
        news_info['source'] = news_source[0]

        list_of_news.append(news_info)

    return list_of_news


def get_yandex_news(dom):
    list_of_news = []
    news_list = dom.xpath("//div[contains(@class, 'mg-card_flexible')]")

    for news in news_list:
        news_info = {}

        name_of_the_news = news.xpath(".//a[@class='mg-card__link']/text()")
        news_link = news.xpath(".//a[@class='mg-card__link']/@href")
        news_date = news.xpath(".//span[@class='mg-card-source__time']/text()")
        news_source = news.xpath(".//a[@class='mg-card__source-link']/text()")

        news_info['source'] = news_source[0]
        news_info['name'] = validate_data(name_of_the_news[0])
        news_info['link'] = news_link[0]
        news_info['date'] = f'{date.today()}T{news_date[0]}+03:00'

        list_of_news.append(news_info)
    return list_of_news


def get_news_data(site, db):
    url = create_url(site)
    print(url)
    response = get_response(url)
    dom = html.fromstring(response.text)

    if site == 'lenta.ru':
        news_data = get_lenta_news(dom)
    elif site == 'news.mail.ru':
        news_data = get_mail_ru_news(dom)
    elif site == 'yandex.ru/news':
        news_data = get_yandex_news(dom)

    pprint(news_data)

    # скалидруем в ящик пандоры :)
    news_collection = db.get_collection('news')
    for data in news_data:
        save_result_in_db(data, news_collection)


def main():
    args = validate_arguments()

    # идём в БиДе!
    client = connect_2_db_server()
    if client:
        db = client['top_news']
    else:
        print('Соединение с базой данных не установлено')

    # в зависимости от полученного 1 сайта или списка начинаем колдовать
    if isinstance(args['site'], list):
        for item in args['site']:
            get_news_data(item, db)
    else:
        get_news_data(args['site'], db)


if __name__ == '__main__':
    main()